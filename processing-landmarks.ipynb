{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:19:23.381452Z",
     "start_time": "2019-05-05T20:19:22.875162Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from urllib import request, error\n",
    "import urllib\n",
    "import imageio\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T19:49:54.053090Z",
     "start_time": "2019-05-05T19:49:43.413Z"
    }
   },
   "source": [
    "### Creating csv that has top 16 landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:  (1193114, 3)\n",
      "Number of landmarks:  (14947, 2)\n",
      "[[ 9633 49525]\n",
      " [ 6051 49306]\n",
      " [ 6599 22811]\n",
      " [ 9779 18096]\n",
      " [ 2061 13020]\n",
      " [ 5554 10819]\n",
      " [ 6651  9307]\n",
      " [ 5376  9061]\n",
      " [ 6696  9050]\n",
      " [ 4352  8839]\n",
      " [ 2743  8838]\n",
      " [13526  8525]\n",
      " [ 1553  7664]\n",
      " [10900  6838]\n",
      " [ 8063  6496]\n",
      " [ 8429  6329]]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train = train[train['landmark_id'] != 'None']\n",
    "train['landmark_id'] = pd.to_numeric(train['landmark_id'])\n",
    "print('Original shape: ', train.shape)\n",
    "landmark_counts = np.array(Counter(train['landmark_id']).most_common())\n",
    "landmark_counts = landmark_counts.astype(np.int)\n",
    "print('Number of landmarks: ', landmark_counts.shape)\n",
    "landmark_counts = landmark_counts[landmark_counts[:,1] >= 6000] #6000 has 16 classes\n",
    "print('Landmark counts: ', landmark_counts)\n",
    "print('Number of images with 6000 per class: ', len(landmark_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmark:  9633\n",
      "Landmark:  6051\n",
      "Landmark:  6599\n",
      "Landmark:  9779\n",
      "Landmark:  2061\n",
      "Landmark:  5554\n",
      "Landmark:  6651\n",
      "Landmark:  5376\n",
      "Landmark:  6696\n",
      "Landmark:  4352\n",
      "Landmark:  2743\n",
      "Landmark:  13526\n",
      "Landmark:  1553\n",
      "Landmark:  10900\n",
      "Landmark:  8063\n",
      "Landmark:  8429\n",
      "New shape:  (32000, 3)\n"
     ]
    }
   ],
   "source": [
    "allTrain = pd.DataFrame()\n",
    "for i in range(len(landmark_counts)):\n",
    "    landmark_index = np.where(train['landmark_id'] == landmark_counts[i][0])[0]\n",
    "    print('Landmark: ', landmark_counts[i][0])\n",
    "#     for j in range(2000): # I divided getting the images into 2 sessions: 32,000 the first time & 32,000 the second\n",
    "    for j in range(2000, 4000):\n",
    "        allTrain = allTrain.append(train.iloc[[landmark_index[j]]])\n",
    "\n",
    "print('New shape: ', allTrain.shape)\n",
    "\n",
    "# to csv\n",
    "allTrain.to_csv('allTrain2000+2000.csv', encoding='utf-8', index=False)\n",
    "allTrain = allTrain.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 3)\n"
     ]
    }
   ],
   "source": [
    "allTrain = pd.read_csv('allTrain2000+2000.csv')\n",
    "print(allTrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating image & label arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n",
      "30700\n",
      "30800\n",
      "30900\n",
      "31000\n",
      "31100\n",
      "31200\n",
      "31300\n",
      "31400\n",
      "31500\n",
      "31600\n",
      "31700\n",
      "31800\n",
      "31900\n",
      "Took:  51619  seconds\n",
      "Number of invalid URLs:  2340\n",
      "(29660, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "landmark_id = []\n",
    "images = []\n",
    "invalid = 0\n",
    "t0 = time.time()\n",
    "for i in range(len(allTrain)):\n",
    "    if i % 100 == 0 and i != 0:\n",
    "        print(i) # just to check progress\n",
    "    try:\n",
    "        request.urlopen(allTrain['url'][i])\n",
    "    except:\n",
    "        invalid += 1\n",
    "        continue\n",
    "    try:\n",
    "        resp = urllib.request.urlopen(allTrain['url'][i])\n",
    "        arr = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "        arr = cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
    "        arr = cv2.cvtColor(arr , cv2.COLOR_BGR2RGB)\n",
    "        arr = cv2.resize(arr,(64, 64), interpolation=cv2.INTER_AREA)\n",
    "    except:\n",
    "        invalid += 1\n",
    "        continue\n",
    "    arr = np.transpose(arr, (2, 0, 1))\n",
    "    landmark_id.append(int(allTrain['landmark_id'][i]))\n",
    "    images.append(arr)\n",
    "t1 = time.time()\n",
    "print('Took: ', int(t1 - t0), ' seconds')\n",
    "print('Number of invalid URLs: ', invalid)\n",
    "landmark_id = np.array(landmark_id)\n",
    "images = np.array(images)\n",
    "images = images / 255\n",
    "images = (images - 0.5) / 0.5\n",
    "print(images.shape)\n",
    "\n",
    "f = gzip.GzipFile(\"images64+2000.npy.gz\", \"w\") # this is saving the 2nd batch of 32,000 images as the first batch had already been saved\n",
    "np.save(file=f, arr=images)\n",
    "f.close()\n",
    "\n",
    "f = gzip.GzipFile(\"landmark_id64+2000.npy.gz\", \"w\")\n",
    "np.save(file=f, arr=landmark_id)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- There are 6850 invalid URLs for top 16 classes (6000 images per class, 32x32): 6850 <br> -->\n",
    "<!-- There are 1154 invalid URLs for top 16 classes (1000 images per class, 128x128): 1154 <br> -->\n",
    "There are 2764 invalid URLs for top 16 classes (2000 images per class, 64x64, the first 32,000 images): 2764 <br>\n",
    "There are 2340 invalid URLs for top 16 classes (2000 images per class, 64x64, the next 32,000 images): 2340 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58896, 3, 64, 64)\n",
      "(58896,)\n"
     ]
    }
   ],
   "source": [
    "images = np.load('images64.npy')\n",
    "landmark_id = np.load('landmark_id64.npy')\n",
    "\n",
    "# converting the npy files to gz files to save memory space\n",
    "f = gzip.GzipFile(\"images64.npy.gz\", \"w\")\n",
    "np.save(file=f, arr=images)\n",
    "f.close()\n",
    "\n",
    "f = gzip.GzipFile(\"landmark_id64.npy.gz\", \"w\")\n",
    "np.save(file=f, arr=landmark_id)\n",
    "f.close()\n",
    "\n",
    "# combining the two batches of 32,000 images into one file\n",
    "f = gzip.open('images64.npy.gz','r')\n",
    "images = np.array(np.load(f))\n",
    "f = gzip.open('images64+2000.npy.gz','r')\n",
    "images2000 = np.array(np.load(f))\n",
    "images = np.append(images, images2000, axis=0)\n",
    "images = np.array(images)\n",
    "\n",
    "f = gzip.open('landmark_id64.npy.gz','r')\n",
    "landmark_id = np.array(np.load(f))\n",
    "f = gzip.open('landmark_id64+2000.npy.gz','r')\n",
    "landmark_id2000 = np.array(np.load(f))\n",
    "landmark_id = np.append(landmark_id, landmark_id2000, axis=0)\n",
    "landmark_id = np.array(landmark_id)\n",
    "\n",
    "print(images.shape)\n",
    "print(landmark_id.shape)\n",
    "\n",
    "# # saving the gz files that contain 64,000 images\n",
    "f = gzip.GzipFile(\"landmark_id64All.npy.gz\", \"w\")\n",
    "np.save(file=f, arr=landmark_id)\n",
    "f.close()\n",
    "\n",
    "f = gzip.GzipFile(\"images64All.npy.gz\", \"w\")\n",
    "np.save(file=f, arr=landmark_id)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
